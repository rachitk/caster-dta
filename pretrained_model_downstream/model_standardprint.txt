JointGNN(
  (activation): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.1, inplace=False)
  (protein_gnn): SelectableProteinModelWrapper(
    (gnn_model): VectorProteinGNN_LBAModel(
      (activation): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.2, inplace=False)
      (gvp_node): Sequential(
        (0): GVP(
          (wh): Linear(in_features=3, out_features=4, bias=False)
          (ws): Linear(in_features=41, out_features=16, bias=True)
          (wv): Linear(in_features=4, out_features=4, bias=False)
          (wsv): Linear(in_features=16, out_features=4, bias=True)
        )
        (1): LayerNorm(
          (scalar_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
        )
      )
      (gvp_edge): Sequential(
        (0): GVP(
          (wh): Linear(in_features=1, out_features=1, bias=False)
          (ws): Linear(in_features=34, out_features=32, bias=True)
          (wv): Linear(in_features=1, out_features=1, bias=False)
          (wsv): Linear(in_features=32, out_features=1, bias=True)
        )
        (1): LayerNorm(
          (scalar_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
      )
      (gvp_relu): ReLU()
      (conv_list): ModuleList(
        (0-1): 2 x GVPConvLayer(
          (conv): GVPConv()
          (norm): ModuleList(
            (0-1): 2 x LayerNorm(
              (scalar_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
            )
          )
          (dropout): ModuleList(
            (0-1): 2 x Dropout(
              (sdropout): Dropout(p=0.2, inplace=False)
              (vdropout): _VDropout()
            )
          )
          (ff_func): Sequential(
            (0): GVP(
              (wh): Linear(in_features=4, out_features=8, bias=False)
              (ws): Linear(in_features=24, out_features=64, bias=True)
              (wv): Linear(in_features=8, out_features=8, bias=False)
              (wsv): Linear(in_features=64, out_features=8, bias=True)
              (scalar_act): ReLU()
            )
            (1): GVP(
              (wh): Linear(in_features=8, out_features=8, bias=False)
              (ws): Linear(in_features=72, out_features=16, bias=True)
              (wv): Linear(in_features=8, out_features=4, bias=False)
              (wsv): Linear(in_features=16, out_features=4, bias=True)
            )
          )
        )
      )
      (gvp_norm_before_scalar): LayerNorm(
        (scalar_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      )
      (gvp_to_scalar): GVP(
        (wh): Linear(in_features=4, out_features=4, bias=False)
        (ws): Linear(in_features=20, out_features=64, bias=True)
        (scalar_act): ReLU()
      )
    )
  )
  (molecule_gnn): SelectableMoleculeModelWrapper(
    (gnn_model): HomoMoleculeGNN_GINE(
      (activation): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv_list): ModuleList(
        (0): GINEConv(nn=MLP(52, 16, 16))
        (1): GINEConv(nn=MLP(16, 64, 64))
      )
    )
  )
  (residue_lins): ModuleList(
    (0): Linear(in_features=64, out_features=128, bias=True)
  )
  (residue_norms): ModuleList(
    (0): Identity()
  )
  (atom_lins): ModuleList(
    (0): Linear(in_features=64, out_features=128, bias=True)
  )
  (atom_norms): ModuleList(
    (0): Identity()
  )
  (cross_attn_module): StackedCrossAttentionModule(
    (cross_attn_layers): ModuleList(
      (0): CrossAttentionModule(
        (preattn_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (preattn_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (embed1_to_2): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (embed2_to_1): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (ff_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (ff_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (ff_dropout): Dropout(p=0.1, inplace=False)
        (ff1): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=256, out_features=128, bias=True)
        )
        (ff2): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=256, out_features=128, bias=True)
        )
      )
    )
  )
  (protein_lins): ModuleList(
    (0): Linear(in_features=128, out_features=256, bias=True)
  )
  (protein_norms): ModuleList(
    (0): Identity()
  )
  (molecule_lins): ModuleList(
    (0): Linear(in_features=128, out_features=256, bias=True)
  )
  (molecule_norms): ModuleList(
    (0): Identity()
  )
  (pm_embed_lin): Linear(in_features=512, out_features=512, bias=True)
  (out_fc_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (out_fc_norms): ModuleList(
    (0): Identity()
  )
  (output_layer): Linear(in_features=256, out_features=1, bias=True)
)
